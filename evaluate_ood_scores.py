# evaluate_ood_scores_debug.py
# (å¢å¼ºç‰ˆï¼šåœ¨å›¾ä¸Šç»˜åˆ¶TNR@TPR=95çš„å†³ç­–é˜ˆå€¼)

import numpy as np
from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve
from scipy.integrate import trapezoid
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# ---------- åŠ è½½å¾—åˆ† ----------
# è¯·ç¡®ä¿è¿™é‡Œçš„æ–‡ä»¶åæ˜¯æ‚¨æ­£åœ¨åˆ†æçš„é‚£ä¸ª
NPZ_FILE = "kuaiceng_ood_scores/bilstm_resflow_53_2.npz"
print(f"[INFO] æ­£åœ¨åŠ è½½å¾—åˆ†æ–‡ä»¶: {NPZ_FILE}")
try:
    data = np.load(NPZ_FILE)
    s_ind, s_ood = data["ind"], data["ood"]
except FileNotFoundError:
    print(f"[ERROR] æ–‡ä»¶ '{NPZ_FILE}' æœªæ‰¾åˆ°ï¼è¯·æ£€æŸ¥è·¯å¾„ã€‚")
    exit()

# ç¡®ä¿æ•°æ®ä¸ä¸ºç©º
if len(s_ind) == 0 or len(s_ood) == 0:
    print("[ERROR] IND æˆ– OOD åˆ†æ•°ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œè¯„ä¼°ã€‚")
    exit()

labels = np.concatenate([np.ones_like(s_ind), np.zeros_like(s_ood)])
scores = np.concatenate([s_ind, s_ood])

# ---------- 1. è®¡ç®—å„é¡¹æŒ‡æ ‡ (é€»è¾‘ä¸ä¹‹å‰ç›¸åŒ) ----------
fpr, tpr, thresholds = roc_curve(labels, scores)
auroc = roc_auc_score(labels, scores)

# æ‰¾åˆ°æ»¡è¶³TPR>=0.95çš„ç¬¬ä¸€ä¸ªç‚¹
# æ·»åŠ ä¸€ä¸ªæ£€æŸ¥ï¼Œä»¥é˜²åœ¨æŸäº›æƒ…å†µä¸‹æ‰¾ä¸åˆ°æ»¡è¶³æ¡ä»¶çš„ç‚¹
tpr95_indices = np.where(tpr >= 0.95)[0]
if len(tpr95_indices) == 0:
    print("[ERROR] æœªèƒ½æ‰¾åˆ°TPR>=0.95çš„é˜ˆå€¼ç‚¹ï¼Œæ— æ³•è®¡ç®—TNR@TPR=95ã€‚")
    tpr95_idx = -1 # ä½¿ç”¨æœ€åä¸€ä¸ªç‚¹ä½œä¸ºå¤‡ç”¨
else:
    tpr95_idx = tpr95_indices[0]

tnr_at_tpr95 = 1 - fpr[tpr95_idx]
decision_threshold = thresholds[tpr95_idx] # <<<<<< è·å–å¯¹åº”çš„å†³ç­–é˜ˆå€¼

y_pred = scores >= decision_threshold
dtacc = (y_pred == labels).mean()

prec_in, rec_in, _ = precision_recall_curve(labels, scores)
rec_in_sorted, prec_in_sorted = zip(*sorted(zip(rec_in, prec_in)))
auin = trapezoid(prec_in_sorted, rec_in_sorted)

prec_out, rec_out, _ = precision_recall_curve(1 - labels, -scores)
rec_out_sorted, prec_out_sorted = zip(*sorted(zip(rec_out, prec_out)))
auout = trapezoid(prec_out_sorted, rec_out_sorted)

# ---------- æ‰“å°ç»“æœ ----------
print("\nâœ… OOD æ£€æµ‹è¯„ä¼°æŒ‡æ ‡ï¼š")
print(f"AUROC          : {auroc:.4f}")
print(f"TNR@TPR=95     : {tnr_at_tpr95:.4f}")
print(f"Detection Acc  : {dtacc:.4f}")
print(f"AUIN           : {auin:.4f}")
print(f"AUOUT          : {auout:.4f}")
print("-" * 20)
print(f"ğŸ“Š è®¡ç®—TNR@TPR=95æ—¶ä½¿ç”¨çš„å†³ç­–é˜ˆå€¼ä¸º: {decision_threshold:.4f}")
print("-" * 20)


# ---------- 2. åˆ†å¸ƒå›¾å¯è§†åŒ– (æ ¸å¿ƒä¿®æ”¹) ----------
df = pd.DataFrame({
    "Score": scores,
    "Type": ["IND"] * len(s_ind) + ["OOD"] * len(s_ood)
})

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x="Score", hue="Type", bins=100, kde=True, stat="density", palette="muted")

# ========== åœ¨å›¾ä¸Šç»˜åˆ¶å†³ç­–é˜ˆå€¼ ==========
plt.axvline(x=decision_threshold, color='red', linestyle='--', linewidth=2,
            label=f'TNR@TPR=95 Threshold = {decision_threshold:.2f}')
# =========================================

plt.title("IND vs OOD Score Distribution with Decision Threshold")
plt.xlabel("Score")
plt.ylabel("Density")
plt.legend()
plt.grid(True)
plt.tight_layout()

output_filename = "score_distribution_with_threshold.png"
plt.savefig(output_filename)
plt.close()

print(f"âœ… å¸¦æœ‰å†³ç­–è¾¹ç•Œçš„åˆ†å¸ƒå›¾å·²ä¿å­˜è‡³: {output_filename}")